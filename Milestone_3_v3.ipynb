{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ae754c0-aa90-408f-a65c-57ff7a953424",
   "metadata": {},
   "source": [
    "# Welcome to our Group Project - Milestone 3 Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c71d7-b145-4b78-8c89-d97a738a84bf",
   "metadata": {},
   "source": [
    "### Step 0 - Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca489fd-c298-470e-8f9c-911c55241749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, glob\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652bad51-a85f-4e10-9085-43c6ed25df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkSession.builder \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .config(\"spark.executor.memory\", \"6g\") \\\n",
    "    .config('spark.executor.instances', 19) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722fd31-ab66-488a-872a-3b76f34972ed",
   "metadata": {},
   "source": [
    "### Step 1 - Loading dataset (Please skip to Step 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd715859-2176-4902-8b06-0ba0a1d243e6",
   "metadata": {},
   "source": [
    "Someone removed all my previous work, including the data and preprocessing/exlporation notebook. So we get to do that all over again here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e9c4f6-2bad-4e47-94e0-0f39eb445ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=12ZvsKXcPKDo3QWBU3_MH4zKG_mp4AU2q\n",
      "From (redirected): https://drive.google.com/uc?id=12ZvsKXcPKDo3QWBU3_MH4zKG_mp4AU2q&confirm=t&uuid=498129fe-3431-4609-8d7d-682026467cf5\n",
      "To: /home/ntorno/group_project/train-00000-of-00016-46dd69ab3f79b370.parquet\n",
      "100%|██████████| 346M/346M [00:05<00:00, 64.8MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1js9jjq6_sED0iCJ7XyYm5nT6OZKnZrB6\n",
      "From (redirected): https://drive.google.com/uc?id=1js9jjq6_sED0iCJ7XyYm5nT6OZKnZrB6&confirm=t&uuid=611c5e5b-d730-4df7-b1db-5efbc3506c68\n",
      "To: /home/ntorno/group_project/train-00000-of-00140-734d6ddb1e9e1773.parquet\n",
      "100%|██████████| 453M/453M [00:06<00:00, 71.6MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1fvNnt5FFJvl_sDbhDRPmlLqnD5xaU_Eu\n",
      "From (redirected): https://drive.google.com/uc?id=1fvNnt5FFJvl_sDbhDRPmlLqnD5xaU_Eu&confirm=t&uuid=54f5ecce-4979-48c2-b33a-275db7c5cfe6\n",
      "To: /home/ntorno/group_project/train-00000-of-00250-e76da37f2b93c542.parquet\n",
      "100%|██████████| 452M/452M [00:06<00:00, 65.7MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1AuZHBpehRQD_1F2JJZj4OlSnHx39qJwm\n",
      "From (redirected): https://drive.google.com/uc?id=1AuZHBpehRQD_1F2JJZj4OlSnHx39qJwm&confirm=t&uuid=0ba778b9-d5be-4c50-a355-7bbed02f60c0\n",
      "To: /home/ntorno/group_project/train-00001-of-00016-b428e1a9775430e8.parquet\n",
      "100%|██████████| 434M/434M [00:06<00:00, 64.8MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1zPNEXEtESsb1jR4SxFFKAHM6EHwa4aEp\n",
      "From (redirected): https://drive.google.com/uc?id=1zPNEXEtESsb1jR4SxFFKAHM6EHwa4aEp&confirm=t&uuid=9b456567-593c-4d85-9529-ae67048cd373\n",
      "To: /home/ntorno/group_project/train-00001-of-00140-e137d78bfa2fb7b1.parquet\n",
      "100%|██████████| 394M/394M [00:05<00:00, 74.3MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1h_6aYEHUKoYjsiiSdFjbn0Qjn2KFtd30\n",
      "From (redirected): https://drive.google.com/uc?id=1h_6aYEHUKoYjsiiSdFjbn0Qjn2KFtd30&confirm=t&uuid=de0b4e76-b9c7-4165-b986-01f22f0dbd2c\n",
      "To: /home/ntorno/group_project/train-00001-of-00250-94a6ed5a243595ce.parquet\n",
      "100%|██████████| 469M/469M [00:06<00:00, 70.4MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1oHvnsmdiBnt2Y2tCHHtLc6IIeORkYs-Z\n",
      "From (redirected): https://drive.google.com/uc?id=1oHvnsmdiBnt2Y2tCHHtLc6IIeORkYs-Z&confirm=t&uuid=dc2e95fc-2c2d-4924-bfc6-474ed9a175bb\n",
      "To: /home/ntorno/group_project/train-00002-of-00016-3a461b7b2d37d5fd.parquet\n",
      "100%|██████████| 328M/328M [00:04<00:00, 71.5MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1JOAFyfPTA9Ougr6-SIQCT3wGosJOBuHN\n",
      "From (redirected): https://drive.google.com/uc?id=1JOAFyfPTA9Ougr6-SIQCT3wGosJOBuHN&confirm=t&uuid=327374c4-ab48-49c7-bcbc-2d2702dce224\n",
      "To: /home/ntorno/group_project/train-00002-of-00140-d69dd45872f01703.parquet\n",
      "100%|██████████| 311M/311M [00:04<00:00, 64.0MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1lwsZwRw9kv2KbOFP-64sXyUgts5YbG3F\n",
      "From (redirected): https://drive.google.com/uc?id=1lwsZwRw9kv2KbOFP-64sXyUgts5YbG3F&confirm=t&uuid=f8434298-07de-416f-a984-f20feef109d8\n",
      "To: /home/ntorno/group_project/train-00002-of-00250-c11203f7e7450eba.parquet\n",
      "100%|██████████| 460M/460M [00:07<00:00, 59.4MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=19SjlTxWAXjoao9mfpIntShk_qd-4Dlym\n",
      "From (redirected): https://drive.google.com/uc?id=19SjlTxWAXjoao9mfpIntShk_qd-4Dlym&confirm=t&uuid=ff3313e6-8bff-4a8a-b29f-30200f529a01\n",
      "To: /home/ntorno/group_project/train-00003-of-00016-2fb25a8f96da7736 (1).parquet\n",
      "100%|██████████| 311M/311M [00:05<00:00, 56.0MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1JYHLj6WynqVl2X2g9zdYHlMqlotyUj61\n",
      "From (redirected): https://drive.google.com/uc?id=1JYHLj6WynqVl2X2g9zdYHlMqlotyUj61&confirm=t&uuid=91d60fb6-30ee-482d-99ff-3e6176b1242b\n",
      "To: /home/ntorno/group_project/train-00003-of-00140-3a63e47707fed41b.parquet\n",
      "100%|██████████| 357M/357M [00:05<00:00, 67.6MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1_0KtcvJKhLvWRuTCncnHJJB02juVtMO0\n",
      "From (redirected): https://drive.google.com/uc?id=1_0KtcvJKhLvWRuTCncnHJJB02juVtMO0&confirm=t&uuid=4053ca08-2e4d-4201-a1be-f03e5b15ad28\n",
      "To: /home/ntorno/group_project/train-00003-of-00250-0a15192a19f12469.parquet\n",
      "100%|██████████| 450M/450M [00:06<00:00, 67.1MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=108QyrKdDZRbRCxQimd6wNYp-WWtX4hUz\n",
      "From (redirected): https://drive.google.com/uc?id=108QyrKdDZRbRCxQimd6wNYp-WWtX4hUz&confirm=t&uuid=0ad9338f-a084-42f7-8386-f8aff7a4e438\n",
      "To: /home/ntorno/group_project/train-00004-of-00016-5d32ac955e739b19.parquet\n",
      "100%|██████████| 423M/423M [00:05<00:00, 76.0MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1LLSjw138Uyim3jGDZvJiarntrcdryOOe\n",
      "From (redirected): https://drive.google.com/uc?id=1LLSjw138Uyim3jGDZvJiarntrcdryOOe&confirm=t&uuid=cf3b1488-7d87-414e-a953-6dc5836b78b6\n",
      "To: /home/ntorno/group_project/train-00004-of-00140-3d83247fdfa22fb5.parquet\n",
      "100%|██████████| 482M/482M [00:07<00:00, 65.4MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1X-BBSszY6n67zchWa6tLC7ZBuo8dN9Yv\n",
      "From (redirected): https://drive.google.com/uc?id=1X-BBSszY6n67zchWa6tLC7ZBuo8dN9Yv&confirm=t&uuid=a2c063a3-2d0b-4221-b602-1df4551a1fe1\n",
      "To: /home/ntorno/group_project/train-00004-of-00250-5f4359daa20f137d.parquet\n",
      "100%|██████████| 436M/436M [00:05<00:00, 78.3MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1qVukEWT7SmQ7CLVTrSHEUPrFx0bunILx\n",
      "From (redirected): https://drive.google.com/uc?id=1qVukEWT7SmQ7CLVTrSHEUPrFx0bunILx&confirm=t&uuid=7706c579-7760-4c7d-a3a6-e26e3669f031\n",
      "To: /home/ntorno/group_project/train-00005-of-00016-939cef8ffe848057.parquet\n",
      "100%|██████████| 467M/467M [00:06<00:00, 75.7MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1jUtSoht5nD5S0GdD3LaDrr7_Nvcr11rT\n",
      "From (redirected): https://drive.google.com/uc?id=1jUtSoht5nD5S0GdD3LaDrr7_Nvcr11rT&confirm=t&uuid=bb718512-3342-4b20-b40f-0c364e627fa8\n",
      "To: /home/ntorno/group_project/train-00005-of-00140-83dc3adb75a2ceab.parquet\n",
      "100%|██████████| 260M/260M [00:04<00:00, 61.6MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1LL6oOs0K6serggFaF_GaGw02uDvcylSE\n",
      "From (redirected): https://drive.google.com/uc?id=1LL6oOs0K6serggFaF_GaGw02uDvcylSE&confirm=t&uuid=9e1dc232-cf3f-49eb-a33e-ee9bd88b612a\n",
      "To: /home/ntorno/group_project/train-00005-of-00250-0283d058bef643bd.parquet\n",
      "100%|██████████| 367M/367M [00:04<00:00, 75.1MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1OXNIaFGcrBMl5i3f_y2j-H_gks5M4Log\n",
      "From (redirected): https://drive.google.com/uc?id=1OXNIaFGcrBMl5i3f_y2j-H_gks5M4Log&confirm=t&uuid=db8d7c95-2ffd-487d-bc1f-3b138e24ec1f\n",
      "To: /home/ntorno/group_project/train-00006-of-00016-aa7ec17a16dbf016.parquet\n",
      "100%|██████████| 397M/397M [00:05<00:00, 69.4MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1DI66r9ic_zacDwL4jIJww6IG3M6jfx6m\n",
      "From (redirected): https://drive.google.com/uc?id=1DI66r9ic_zacDwL4jIJww6IG3M6jfx6m&confirm=t&uuid=82dcffdd-6eac-41ab-8286-52cb827ad80c\n",
      "To: /home/ntorno/group_project/train-00006-of-00140-ed5342fe71756bf9.parquet\n",
      "100%|██████████| 277M/277M [00:05<00:00, 50.6MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1oGanekYhzt7ZMV72n7tRceNcj1od7eMW\n",
      "From (redirected): https://drive.google.com/uc?id=1oGanekYhzt7ZMV72n7tRceNcj1od7eMW&confirm=t&uuid=0875e2ff-5a22-4710-aff3-c15102cef811\n",
      "To: /home/ntorno/group_project/train-00006-of-00250-309c61a911187d72.parquet\n",
      "100%|██████████| 362M/362M [00:05<00:00, 63.4MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Run this section only to download the dataset the first time\n",
    "import gdown\n",
    "\n",
    "# This is taking in the google drive file ID for each BIOMEDICA file we want to upload\n",
    "parquet_files = [\n",
    "    \"12ZvsKXcPKDo3QWBU3_MH4zKG_mp4AU2q\", \n",
    "    \"1js9jjq6_sED0iCJ7XyYm5nT6OZKnZrB6\", \n",
    "    \"1fvNnt5FFJvl_sDbhDRPmlLqnD5xaU_Eu\", \n",
    "    \"1AuZHBpehRQD_1F2JJZj4OlSnHx39qJwm\", \n",
    "    \"1zPNEXEtESsb1jR4SxFFKAHM6EHwa4aEp\", \n",
    "    \"1h_6aYEHUKoYjsiiSdFjbn0Qjn2KFtd30\",\n",
    "    \"1oHvnsmdiBnt2Y2tCHHtLc6IIeORkYs-Z\", \n",
    "    \"1JOAFyfPTA9Ougr6-SIQCT3wGosJOBuHN\",\n",
    "    \"1lwsZwRw9kv2KbOFP-64sXyUgts5YbG3F\", \n",
    "    \"19SjlTxWAXjoao9mfpIntShk_qd-4Dlym\", \n",
    "    \"1JYHLj6WynqVl2X2g9zdYHlMqlotyUj61\",\n",
    "    \"1_0KtcvJKhLvWRuTCncnHJJB02juVtMO0\",\n",
    "    \"108QyrKdDZRbRCxQimd6wNYp-WWtX4hUz\",\n",
    "    \"1LLSjw138Uyim3jGDZvJiarntrcdryOOe\",\n",
    "    \"1X-BBSszY6n67zchWa6tLC7ZBuo8dN9Yv\",\n",
    "    \"1qVukEWT7SmQ7CLVTrSHEUPrFx0bunILx\",\n",
    "    \"1jUtSoht5nD5S0GdD3LaDrr7_Nvcr11rT\",\n",
    "    \"1LL6oOs0K6serggFaF_GaGw02uDvcylSE\",\n",
    "    \"1OXNIaFGcrBMl5i3f_y2j-H_gks5M4Log\",\n",
    "    \"1DI66r9ic_zacDwL4jIJww6IG3M6jfx6m\",\n",
    "    \"1oGanekYhzt7ZMV72n7tRceNcj1od7eMW\",\n",
    "]\n",
    "\n",
    "# Download all files listed above\n",
    "for fid in parquet_files:\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={fid}\", quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca921db4-2969-4daa-a2d5-1b7b2a453cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first have to create a local path before saving files to the remote directory\n",
    "import os\n",
    "\n",
    "base_dir = os.path.expanduser('~/group_project/parquet_data')\n",
    "\n",
    "# Create the directory\n",
    "os.makedirs(base_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e735fa10-c32f-4357-895a-ad6d9e0047a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train-00003-of-00250-0a15192a19f12469.parquet', 'train-00004-of-00250-5f4359daa20f137d.parquet', 'train-00002-of-00140-d69dd45872f01703.parquet', 'BIOMEDICA___biomedica_histopathology_subset_parquet', 'train-00004-of-00140-3d83247fdfa22fb5.parquet', 'Milestone_3.ipynb', 'train-00005-of-00140-83dc3adb75a2ceab.parquet', '_home_ntorno_group_project_BIOMEDICA___biomedica_histopathology_subset_parquet_default_0.0.0_b7b86b71823e47f25e18a8bbbd0195292d930802.lock', 'train-00003-of-00016-2fb25a8f96da7736 (1).parquet', 'train-00006-of-00016-aa7ec17a16dbf016.parquet', 'train-00005-of-00016-939cef8ffe848057.parquet', 'train-00003-of-00140-3a63e47707fed41b.parquet', 'train-00001-of-00140-e137d78bfa2fb7b1.parquet', '.ipynb_checkpoints', 'train-00002-of-00016-3a461b7b2d37d5fd.parquet', 'train-00000-of-00140-734d6ddb1e9e1773.parquet', 'train-00001-of-00250-94a6ed5a243595ce.parquet', 'train-00006-of-00250-309c61a911187d72.parquet', 'train-00002-of-00250-c11203f7e7450eba.parquet', 'train-00005-of-00250-0283d058bef643bd.parquet', 'train-00004-of-00016-5d32ac955e739b19.parquet', 'train-00006-of-00140-ed5342fe71756bf9.parquet', 'train-00000-of-00016-46dd69ab3f79b370.parquet', 'train-00000-of-00250-e76da37f2b93c542.parquet', 'train-00001-of-00016-b428e1a9775430e8.parquet']\n"
     ]
    }
   ],
   "source": [
    "# Make sure the parquet files are in the new directory\n",
    "import os\n",
    "print(os.listdir(os.path.expanduser('~/ntorno/group_project/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "970ebb9f-de7c-40b9-8067-bac36e33001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_dir = os.path.expanduser('~/ntorno/group_project/')\n",
    "\n",
    "# Load all parquet files in this directory\n",
    "parquet_files = parquet_dir + \"/*.parquet\" \n",
    "df = sc.read.parquet(parquet_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bcf5e65-cc0b-467e-ad18-a566728a2d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34945"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30990b89-7487-4f64-82bc-6bd75877685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined dataframe\n",
    "output_dir = os.path.expanduser('~/group_project/parquet_datasets/biomedica_histopathology')\n",
    "df.write.mode('overwrite').parquet(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86b2b46-b48c-4f87-914b-32910969afac",
   "metadata": {},
   "source": [
    "### Step 2 - Preprocess Data for CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38804439-4c8b-4b81-a927-fe7d8d9dc736",
   "metadata": {},
   "source": [
    "Please note that this skips over the exploratory analysis because that was included in Milestone 2. Please check your working directory before proceeding as you may have to use a different file path if you are working in a cloned directory. You can check your working directory in terminal using pwd before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b11c5a3-a1fc-48fe-a436-3bc80ab12a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# PLEASE NOTE\n",
    "# If you accessing this project in a cloned directory, you should skip this cell and use the path in the following cell instead\n",
    "data = sc.read.parquet(os.path.expanduser('~/group_project/parquet_datasets/biomedica_histopathology'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e9cec-4856-41ac-8ca7-a76a86a3cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are not working directly in this path: /expanse/lustre/projects/uci150/ntorno/group_project\n",
    "# For example, your path might look like \"~/your_name/notrno/group_project\" if you cloned this project into your directory\n",
    "# Please load the data using this code instead\n",
    "# data = sc.read.parquet(os.path.expanduser('~/ntorno/group_project/parquet_datasets/biomedica_histopathology'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bcdbb36-b00b-4fc5-bc19-a52765c592f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34945"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b495a6f9-0519-40df-b1e1-a8cbc61315a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[image: struct<bytes:binary,path:string>, caption: string, image_id: string, image_cluster_id: string, image_hash: string, image_file_name: string, image_panel_type: string, image_panel_subtype: string, image_primary_label: array<string>, image_secondary_label: array<string>, image_size: array<int>, image_figure_set: string, image_context: string, article_title: string, article_keywords: array<string>, article_journal: string, article_date: string, article_abstract: string, article_mesh_terms: array<string>, subset: string, pmid: string, article_reference_ids: array<string>, article_reference_count: string, article_reference_list: array<string>, article_citation: string, article_license: string]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eef615a5-26da-4b4f-b1f7-a458f249645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are beginning with a small local test\n",
    "sample_data = data.select(\"image.bytes\", \"image_primary_label\").limit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbe67a08-cbf4-41e5-bc5f-92511df54d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3c6f578-6f4c-48af-9205-db2a29a9ac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data preprocessing\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def decode_and_resize(img_bytes, target_size = (128, 128)):\n",
    "    img = Image.open(io.BytesIO(img_bytes)).convert('RGB')\n",
    "    img = img.resize(target_size)\n",
    "    return np.array(img)\n",
    "\n",
    "rows = sample_data.collect()\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for row in rows:\n",
    "    try:\n",
    "        img_bytes = row['bytes']\n",
    "        img_array = decode_and_resize(img_bytes)\n",
    "        X_list.append(img_array)\n",
    "        \n",
    "        label = row['image_primary_label'][0] if row['image_primary_label'] else 'unknown'\n",
    "        y_list.append(label)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "X = np.stack(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0aacf7b-b668-4c0f-ba1b-d182ba046d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_list)\n",
    "\n",
    "# Convert to one-hot vectors \n",
    "num_classes = len(label_encoder.classes_)\n",
    "y = to_categorical(y_encoded, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96d6d463-f371-45a6-aef8-b2f6143e170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale pixel values for better performance\n",
    "X = X.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a918d21-68e7-47d0-ae3a-4d5d76ff72e9",
   "metadata": {},
   "source": [
    "Test toy CNN - I'm really just checking that tensorflow downloaded properly here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de9f321c-f15c-4518-a82c-84424abf02e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntorno/.local/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Pyspark Mlib does not support CNNs directly, so we will use tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_shape = X.shape[1:]  # e.g. (128, 128, 3)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=input_shape),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6343e9d1-0125-4fa4-9a00-4a0995c8ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.2, random_state = 42, stratify = y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd6ad375-2413-4a09-8fe3-04092821c492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1554cc5ce9d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, y, epochs = 10, batch_size = 32, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc00c066-6b5e-4d62-8791-46b69f483f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Test Loss: 0.0000\n",
      "Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model accuracy\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "891fed9a-ffff-457e-8826-fb26515976a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Microscopy       1.00      1.00      1.00       200\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predict labels\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Label names\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true, y_pred, target_names = class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7302ea0-a42a-411b-a033-7419e8962431",
   "metadata": {},
   "source": [
    "### Step 3 - Build, Train, and Evaluate CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26e047e-6fe7-4062-be0d-7341978e4fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique articles: 28644\n"
     ]
    }
   ],
   "source": [
    "unique_article_count = data.select('article_title').distinct().count()\n",
    "print(f\"Number of unique articles: {unique_article_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f0b4b2-ab78-4cf2-9d0c-4e2303be8ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|article_title                                                                                                                                    |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Bronchiolitis Obliterans Organizing Pneumonia in Swine Associated with Porcine Circovirus Type 2 Infection                                       |\n",
      "|Comparison of pain behaviour and osteoarthritis progression between anterior cruciate ligament transection and osteochondral injury in rat models|\n",
      "|Involvement of Endoplasmic Reticulum Stress in Myocardial Apoptosis of Streptozocin-Induced Diabetic Rats                                        |\n",
      "|Survey of Supervised Learning for Medical Image Processing                                                                                       |\n",
      "|in situ O The  distribution of glycoprotein-bound 4--Acetylated sialic acids in vertebrates                                                      |\n",
      "|Notch as a Possible Cell Differentiation Factor in Pleomorphic Adenomas                                                                          |\n",
      "|Autoimmune inflammatory rheumatic diseases post-COVID‐19 vaccination                                                                             |\n",
      "|Multimodal treatment for resectable epithelial type malignant pleural mesothelioma                                                               |\n",
      "|Infusion of Graphene Quantum Dots to Create Stronger,\\nTougher, and Brighter Polymer Composites                                                  |\n",
      "|Subepithelial telocytes are an important source of Wnts that supports intestinal crypts                                                          |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_articles = data.select('article_title').distinct()\n",
    "unique_articles.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbd3c4f1-2609-49c7-8f14-c7dcc4d1556d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique journals: 3044\n"
     ]
    }
   ],
   "source": [
    "unique_journal_count = data.select('article_journal').distinct().count()\n",
    "print(f\"Number of unique journals: {unique_journal_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75bd2dbb-177e-40f0-ba41-a02876f6c743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|article_journal           |\n",
      "+--------------------------+\n",
      "|Environ Sci Pollut Res Int|\n",
      "|Clin Med Insights Case Rep|\n",
      "|Vasc Health Risk Manag    |\n",
      "|ACS Chem Biol             |\n",
      "|Appl Environ Microbiol    |\n",
      "|Ann Anat                  |\n",
      "|Clin Ophthalmol           |\n",
      "|Int J Med Sci             |\n",
      "|Cancer Biol Med           |\n",
      "|Int J Parasitol           |\n",
      "+--------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_journals = data.select('article_journal').distinct()\n",
    "unique_journals.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74459adc-983a-4bc1-9ca2-a38d3774864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a70f2a09-2202-4d24-8fe8-d939ee7d4d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc9c8baa-5d22-4710-be02-4406bac70a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data preprocessing\n",
    "from PIL import Image\n",
    "import io\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def decode_and_resize(img_bytes, target_size=(128, 128)):\n",
    "    img = Image.open(io.BytesIO(img_bytes)).convert('RGB')\n",
    "    img = img.resize(target_size)\n",
    "    return np.array(img)\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for row in data.toLocalIterator():\n",
    "    try:\n",
    "        img_bytes = row.image.bytes \n",
    "        img_array = decode_and_resize(img_bytes)\n",
    "        X_list.append(img_array)\n",
    "\n",
    "        label = row.article_journal[0] if row.article_journal else 'unknown'\n",
    "        y_list.append(label)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping row due to error: {e}\")\n",
    "        continue\n",
    "\n",
    "X = np.stack(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83d09581-e2eb-492a-a196-6a61ccf62f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_list)\n",
    "\n",
    "# Convert to one-hot vectors \n",
    "num_classes = len(label_encoder.classes_)\n",
    "y = to_categorical(y_encoded, num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e012293-3191-4074-80c0-bce259785b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale pixel values for better performance\n",
    "X = X.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f31c8a85-ccd3-44ee-a85d-27c48236a8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntorno/.local/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Pyspark Mlib does not support CNNs directly, so we will use tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape = input_shape),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(num_classes, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "556cca95-7151-4633-8414-a7d1cb1f6c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.2, random_state = 42, stratify = y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfa91d05-ab36-4ac3-8313-9fb430ec851b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 118ms/step - accuracy: 0.1410 - loss: 2.9649 - val_accuracy: 0.1298 - val_loss: 2.8702\n",
      "Epoch 2/13\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 118ms/step - accuracy: 0.1597 - loss: 2.8197 - val_accuracy: 0.1411 - val_loss: 2.8570\n",
      "Epoch 3/13\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 120ms/step - accuracy: 0.1803 - loss: 2.7503 - val_accuracy: 0.1345 - val_loss: 2.8683\n",
      "Epoch 4/13\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 131ms/step - accuracy: 0.2232 - loss: 2.5780 - val_accuracy: 0.1282 - val_loss: 3.0497\n",
      "Epoch 5/13\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 131ms/step - accuracy: 0.3399 - loss: 2.1928 - val_accuracy: 0.1127 - val_loss: 3.4956\n",
      "Epoch 6/13\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 131ms/step - accuracy: 0.4930 - loss: 1.6676 - val_accuracy: 0.1095 - val_loss: 4.4572\n",
      "Epoch 7/13\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 131ms/step - accuracy: 0.6454 - loss: 1.1883 - val_accuracy: 0.1027 - val_loss: 6.0894\n",
      "Epoch 8/13\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 132ms/step - accuracy: 0.7666 - loss: 0.8068 - val_accuracy: 0.1023 - val_loss: 7.7270\n",
      "Epoch 9/13\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 134ms/step - accuracy: 0.8539 - loss: 0.5146 - val_accuracy: 0.0900 - val_loss: 9.2416\n",
      "Epoch 10/13\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 138ms/step - accuracy: 0.9016 - loss: 0.3651 - val_accuracy: 0.0953 - val_loss: 10.4501\n",
      "Epoch 11/13\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 144ms/step - accuracy: 0.9331 - loss: 0.2555 - val_accuracy: 0.0977 - val_loss: 11.7082\n",
      "Epoch 12/13\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 144ms/step - accuracy: 0.9575 - loss: 0.1781 - val_accuracy: 0.0972 - val_loss: 12.5437\n",
      "Epoch 13/13\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 131ms/step - accuracy: 0.9662 - loss: 0.1431 - val_accuracy: 0.1030 - val_loss: 13.9097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1554ca0cff50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, y, epochs = 13, batch_size = 32, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44a6e27e-db47-4ca6-9f82-8e64a3ac2d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8070 - loss: 2.9719\n",
      "Test Loss: 2.7943\n",
      "Test Accuracy: 0.8096\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model accuracy\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba93c0ee-a5bc-46c2-8dc4-f7fd3c33ad10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.79      0.79      0.79       634\n",
      "           B       0.80      0.73      0.76       471\n",
      "           C       0.79      0.81      0.80       492\n",
      "           D       0.85      0.82      0.84       199\n",
      "           E       0.80      0.83      0.82       266\n",
      "           F       0.83      0.81      0.82       321\n",
      "           G       0.84      0.84      0.84        76\n",
      "           H       0.82      0.75      0.78       118\n",
      "           I       0.85      0.84      0.85       582\n",
      "           J       0.81      0.86      0.83       997\n",
      "           K       0.85      0.86      0.86        66\n",
      "           L       0.90      0.84      0.87        90\n",
      "           M       0.71      0.84      0.77       565\n",
      "           N       0.82      0.81      0.82       360\n",
      "           O       0.80      0.81      0.80       239\n",
      "           P       0.84      0.80      0.82       595\n",
      "           Q       1.00      0.40      0.57         5\n",
      "           R       0.85      0.80      0.83       188\n",
      "           S       0.81      0.80      0.81       323\n",
      "           T       0.80      0.75      0.77       129\n",
      "           U       0.97      0.86      0.91        36\n",
      "           V       0.92      0.76      0.83       116\n",
      "           W       1.00      0.70      0.83        37\n",
      "           Y       1.00      0.71      0.83         7\n",
      "           Z       0.86      0.75      0.80         8\n",
      "           b       1.00      0.50      0.67        10\n",
      "           e       0.71      0.68      0.69        37\n",
      "           i       0.78      0.64      0.70        11\n",
      "           m       0.89      0.73      0.80        11\n",
      "\n",
      "    accuracy                           0.81      6989\n",
      "   macro avg       0.85      0.76      0.80      6989\n",
      "weighted avg       0.81      0.81      0.81      6989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predict labels\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Label names\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true, y_pred, target_names = class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c92e70a-8b8a-4635-84a4-4beca32e5dd9",
   "metadata": {},
   "source": [
    "### Step 4 - Consider the fitting graph\n",
    "\n",
    "Because this model achieved over 96.6% training accuracy but only 81% test accuracy, it can be said that the model is in the overfitting section of the model fitting graph. Because the model seems to be overfitting in training, future training considerations will include hyperparameter tuning focused on the learning rate, batch size, and experimenting with different sizes of C to mitigate overfitting. It is not entirely surprising that overfitting is present because the data is so highly dimensional; the model may be able to learn patterns in the training set well at the expense of being able to generalize to new data in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52f4cd7-8725-4ec5-a7e8-a6e68327f18f",
   "metadata": {},
   "source": [
    "### Step 5 - What next models are you thinking of and why?\n",
    "\n",
    "In addition to the hyperparameter tuning mentioned above, one additional model we will implement is a journal cluster based model; we will first use a clustering algorithm to organize journals into similar groups, then use the group labels as the prediction variable instead of the unique journal titles to train the CNN. Because there are over 3,000 different journals represented in the dataset, it is possible that hyperparameter tuning alone may not be enough to overcome how complex the prediction task is. Another option worth pursuing is to leverage the MobileNetV2 model, which is a highly robust pretrained CNN optimized for efficient image classification. More specifically, we will employ transfer learning, meaning the MobileNetV2 model will be combined with information from our dataset by retraining some layers of the model, creating a customizer predictor while still benefitting from the pretrained model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd7c5f-db18-4bb7-83d3-0aff1a4caa69",
   "metadata": {},
   "source": [
    "### Step 6 - Update README\n",
    "\n",
    "This has been done, and the updated information can be viewed in the main branch on GitHub as well as in the Milestone3 branch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb677bc0-43f4-44b6-b414-f1abd6a9f8e8",
   "metadata": {},
   "source": [
    "### Step 7 - Conclusion Section\n",
    "\n",
    "The first model is a successful initial attempt to leverage the BIOMEDICA database to predict which medical journal histopathological images belong to. The model achieved over 96% testing accuracy but 81% testing accuracy, revealing the need for further optimization. This optimization will be addressed in future work using a three-pronged approach: (1) employ hyperparameter tuning of the learning rate, batch size, and C, (2) cluster the journals before training the CNN, and (3) employ transfer learning with the MobileNetV2 model. We recognize that it is entirely possible that these approaches may yield varying degrees of success; for example, hyperparameter tuning is important, but it will never make up for using the wrong model initially. Our group's decision to employ a three-pronged approach to model optimization comes from the desire to try multiple different options and compare the results. This will give us the best chance of creating a strong model without leaving so many \"what-ifs\" at the end of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981cffb-59f9-45f9-bfc8-119292902622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
